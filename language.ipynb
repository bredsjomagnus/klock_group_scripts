{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking language:  28%|██▊       | 190/684 [00:00<00:00, 867.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m     - 1C Al Kadumi, Fatimah SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 1D Alhussein, Mohamad SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 1D Alkisie, Ali SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 1D Alnaami, Nawal SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 1D Andersson, Liv SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 1D Berglund, Sigrid SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 1D Bergström, Siri SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 1D Braimaj, Levina SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 1D Darweesh, Redha SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 1D Elg Ås, Eline SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 1D Eriksson, Elvira SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 1D Haj Mousa, Narjes SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 1D Hall, Fox SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 1D Hansson, Elton SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 1D Hedlund, Noah SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 1D Khalaf, Siamet SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 1D Olsson, Elvira SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 1D Sandberg, Vega SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 1D Sander, Troy SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 1D Smedh, Joline SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 1D Stoor, Arwen SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 1D Ståhl, Linus SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 1D Walstad Andersson, Emilia SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 2D Andersson, Sven SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 2D Bark, Elvin SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 2D Bystedt Bark, Klara SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 2D Darweesh, Sakina SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 2D Elg Ås, Tilde SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 2D Gustafsson, Astrid SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 2D Kjellberg, Amanda SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 2D Krips Bergström, Laura SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 2D Köster, Milo SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 2D Löfgren, Noel SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 2D Nässi, Alva SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 2D Olsson, Viola SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 2D René Bergqvist, Aimée SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 2D Tiurinen, Oliwer SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 3D Alhussein, Maria SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 3D Bark, Emil SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 3D Bergström, Charlie SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 3D Braimaj, Thea SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 3D Elefant Anebo, Lucas SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 3D Eriksson, Vera SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 3D Haj Mousa, Ahmed SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 3D Hassan, Hafso SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 3D Heimburger Grängstedt, My SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 3D Holmqvist, Emil SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 3D Moltsanov, Dmitri SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 3D Niittymäki, Sam SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 3D Nurmela, Charlie SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 3D René Bergqvist, Nelson SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 3D Sander Aarås, William SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 3D Schattkowsky, Jonathan SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 3D Ståhl, Sally SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 3D Voroschenko, Jasmin SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 3D Zambrano Ögren, Leonel SAKNAS I EDUKONTO SHEET\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking language:  56%|█████▋    | 386/684 [00:00<00:00, 915.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m     - 4D Andersson, Oliver SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 4D Braimaj, Jolina SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 4D Braimaj, Leon SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 4D Eriksson, Holly SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 4D Eriksson, Wilmer SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 4D Haikola, Alice SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 4D Haj Mousa, Tamer SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 4D Hermansson, Julia SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 4D Johansson, Hugo SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 4D Kjellberg, Julia SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 4D Lund, Filippa SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 4D Mohamed Hassan, Sumayo SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 4D Nilsson, Alva SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 4D Nilsson, Elin SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 4D Schnaars, Katelin SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 4D Tiurinen, Oscar SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 5D Abrahamsson, Lovisa SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 5D Ak, Eren Azad SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 5D Alashtar, Odai SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 5D Alhussein, Aya SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 5D Bystedt Bark, Oliver SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 5D Dahl, Klara SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 5D Do couto, James SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 5D Höök, Tilde SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 5D Krips Bergström, Leon SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 5D Rundkvist, Alicia SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 5D Rundkvist, Jacob SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 5D Rundkvist, Julia SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 5D Stoor, Zeke SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 6D Ahmed, Guled Gustav SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 6D Alashtar, Adnan SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 6D Braimaj, Tindra SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 6D Do Couto, Amélie SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 6D Filipsson, Buster SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 6D Filipsson, Neo SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 6D Haj Mousa, Abdullatifh SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 6D Hautanen, Alma SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 6D Heimburger Grängstedt, Smilla SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 6D Hidén, Wille SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 6D Mickelsson, Victor SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 6D Norström, Max SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 6D Nurmela, Adam SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 6D Runkvist, Lovisa SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 6D Sol, Melody SAKNAS I EDUKONTO SHEET\u001b[0m\n",
      "\u001b[33m     - 6D Wolke, Nellie SAKNAS I EDUKONTO SHEET\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking language: 100%|██████████| 684/684 [00:00<00:00, 976.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     [Saved info about missing language to file \u001b[36m'2020-11-25_språk_som_saknas.csv']\u001b[0m\n",
      "684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "from config import *\n",
    "from functions import *\n",
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "import getopt\n",
    "import pickle\n",
    "import os.path\n",
    "from env import *\n",
    "from termcolor import colored, cprint\n",
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "\n",
    "def prepp_df_dict(_dict, org_header):\n",
    "    checks_out = True\n",
    "    res = {}\n",
    "    header = []\n",
    "    for key, value in _dict.items():\n",
    "        res[value] = []\n",
    "        header.append(key)\n",
    "        if not key in org_header:\n",
    "            print(f'{key} not checking out')\n",
    "            checks_out = False\n",
    "    return res, header, checks_out\n",
    "\n",
    "def get_sheet_values_service(service, ID, _range):\n",
    "    sheet = service.spreadsheets()\n",
    "    result = sheet.values().get(spreadsheetId=ID, range=_range).execute()\n",
    "    return result.get('values', [])\n",
    "\n",
    "def get_sheet_as_df(service, ID, _range, col_map):\n",
    "    \"\"\"\n",
    "    Hämtar ett sheet från Drive med id ID inom range _range och med\n",
    "    header mapping enlig col_map.\n",
    "    \n",
    "    Returnerar DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    values = get_sheet_values_service(service, ID, _range)\n",
    "    # Den faktiska headern i sheeten\n",
    "    org_header = values[0]\n",
    "    \n",
    "    if not values:\n",
    "        print('No data found in ' + ID + ', range ' + _range + ' with col_map ' + col_map)\n",
    "    else:\n",
    "        errors = []\n",
    "        \n",
    "        # Preparerar data:\n",
    "        # _dict (dict) får keys utefter col_map med tom lista som value för varje key.\n",
    "        # header (list) sätts utefter col_map (vilka rubriker som skall extraheras)\n",
    "        # checks_out (boolean) True om col_map keys finns med i org_header annars False\n",
    "        _dict, header, checks_out = prepp_df_dict(col_map, org_header)\n",
    "        \n",
    "        if checks_out:\n",
    "            for i, row in enumerate(values):\n",
    "                if i == 0:\n",
    "                    # Skippar rubrikraden\n",
    "                    pass\n",
    "                else:\n",
    "                    try:\n",
    "                        for key in header:\n",
    "                            # print(f'len(row): {len(row)}')\n",
    "                            # print(f'org_header.index(key): {org_header.index(key)}')\n",
    "                            if len(row) <= org_header.index(key):\n",
    "                                \"\"\"\n",
    "                                Raden som plocks ut (row) blir inte alltid lika lång som rubrikraden utan klipps av till kortare längd om celler mot\n",
    "                                slutet av raden är tomma. Detta gör att man måste kolla om raden är kortare än headerraden för denna rubriken (key)\n",
    "                                och om så är fallet appenda tom cell (''). Detta för att undvika index out of range error.\n",
    "                                \"\"\"\n",
    "                                _dict[col_map[key]].append('')\n",
    "                            else:\n",
    "                                _dict[col_map[key]].append(row[org_header.index(key)])\n",
    "    \n",
    "                    except Exception as e:\n",
    "                        errors.append(row)\n",
    "                            \n",
    "        else:\n",
    "            print(f'{col_map} and {org_header} doesn\\'t match')\n",
    "            exit()\n",
    "    \n",
    "    return pd.DataFrame.from_dict(_dict), errors\n",
    "\n",
    "def find_language(pn, name, df_sva_sv):\n",
    "\n",
    "    language = \"\"\n",
    "    message = \"OK\"\n",
    "    try:\n",
    "        language_series = df_sva_sv[df_sva_sv['Personnummer'].str.contains(pn)]\n",
    "        if len(language_series.index) == 1:\n",
    "            language = str(language_series['Språk'].values[0])\n",
    "        else:\n",
    "            language_series = df_sva_sv[df_sva_sv['Namn'].str.contains(name)]\n",
    "            if len(language_series.index) == 1:\n",
    "                email = str(language_series['Språk'].values[0])\n",
    "            else:\n",
    "                message = \"KONTOT SAKNAS I SVA_SV SHEET\"\n",
    "    except Exception as e:\n",
    "        print(\"Error while looking for email in edukonto sheet \", e)\n",
    "\n",
    "    return language, message\n",
    "\n",
    "def check_language(service, df_elevlista, df_sva_sv, ELEVLISTA_ID):\n",
    "    elevlista_klass_list = df_elevlista.loc[:, \"Klass\"].tolist()\n",
    "    elevlista_namn_list = df_elevlista.loc[:, \"Namn\"].tolist()\n",
    "    elevlista_groups_list = df_elevlista.loc[:, \"Grupper\"].tolist()\n",
    "    elevlista_personnummer_list = df_elevlista.loc[:, \"Personnummer\"].tolist()\n",
    "    elevlista_email_list = df_elevlista.loc[:, \"Mail\"].tolist()\n",
    "\n",
    "    sva_sv_namn_list = df_sva_sv.loc[:, \"Namn\"].tolist()\n",
    "    sva_sv_personnummer_list = df_sva_sv.loc[:, \"Personnummer\"].tolist()\n",
    "    sva_sv_language_list = df_sva_sv.loc[:, \"Språk\"].tolist()\n",
    "\n",
    "    missing_language_klass = [] # for error handling. Will build df and then save missing mails to csv\n",
    "    missing_language_name = []\n",
    "    content = []\n",
    "    for i, current_pn in enumerate(tqdm(elevlista_personnummer_list, desc=\"Checking language\")):\n",
    "        row = []\n",
    "        current_name = elevlista_namn_list[i]\n",
    "        current_klass = elevlista_klass_list[i]\n",
    "        current_groups = elevlista_groups_list[i]\n",
    "        current_email = elevlista_email_list[i]\n",
    "        language, message = find_language(current_pn, current_name, df_sva_sv)\n",
    "        if language == \"\":\n",
    "            pass\n",
    "        if message != \"OK\":\n",
    "            if current_klass in relevent_classes:\n",
    "                cprint(\"     - %s %s SAKNAS I EDUKONTO SHEET\" % (current_klass, current_name), 'yellow')\n",
    "                missing_language_klass.append(current_klass)\n",
    "                missing_language_name.append(current_name)\n",
    "\n",
    "        row = [current_klass, current_name, current_groups, current_pn, current_email, language]\n",
    "\n",
    "        content.append(row)\n",
    "\n",
    "    if len(missing_language_klass) > 0:\n",
    "        missing_language_dict = {\n",
    "            'Klass': missing_language_klass,\n",
    "            'Namn': missing_language_name\n",
    "        }\n",
    "        missing_language_df = pd.DataFrame.from_dict(missing_language_dict)\n",
    "        time_stamp = str(datetime.datetime.now())[:10] # 2019-09-04\n",
    "        filename = time_stamp + '_språk_som_saknas.csv'\n",
    "        try:\n",
    "            missing_language_df.to_csv(filename, sep=\";\", index=False)\n",
    "            print(\"     [Saved info about missing language to file \", end=\"\")\n",
    "            cprint(\"'%s']\" % (filename), 'cyan')\n",
    "        except PermissionError:\n",
    "            print(\n",
    "                f\"     SAVING FILE '{filename}' PERMISSION ERROR: Is file already open?\")\n",
    "        except:\n",
    "            print(\"     Something went wrong!\")\n",
    "            \n",
    "            \n",
    "    return content\n",
    "\n",
    "service = authenticate()\n",
    "\n",
    "ID ='1tnG_zT2AhQk9hTBQYMyrX2_TGSeryHwG1mh96vtdqM4'\n",
    "sheet_name = 'elevlista'\n",
    "col_map = {\n",
    "    'Elev Klass': 'Klass',\n",
    "    'Elev Namn': 'Namn',\n",
    "    'Elev Grupper': 'Grupper',\n",
    "    'Elev Personnummer': 'Personnummer',\n",
    "    'Elev Mail': 'Mail',\n",
    "}\n",
    "\n",
    "df_elevlista, errors = get_sheet_as_df(service, ID, sheet_name+'!A1:E', col_map)\n",
    "\n",
    "# print(df_elevlista);\n",
    "\n",
    "ID ='1tnG_zT2AhQk9hTBQYMyrX2_TGSeryHwG1mh96vtdqM4'\n",
    "sheet_name = 'sva_sv'\n",
    "col_map = {\n",
    "    'Elev': 'Namn',\n",
    "    'Personnummer': 'Personnummer',\n",
    "    'Språk': 'Språk'\n",
    "}\n",
    "\n",
    "df_language, errors = get_sheet_as_df(service, ID, sheet_name+'!A1:E', col_map)\n",
    "\n",
    "content = check_language(service, df_elevlista, df_language, ID)\n",
    "# print(df_language)\n",
    "print(len(content))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
